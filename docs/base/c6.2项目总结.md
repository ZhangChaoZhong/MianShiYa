### 在线人脸识别考勤小程序开发

#### 介绍

该项目采用前后端分离开发模式，前端使用uni-app，后端使用SpringBoot，实现注册登录，人脸考勤签到，系统通知功能。

#### 前后端分离

  从本质上来看前后端分离本身并不是一个技术问题，**不仅仅是一种开发模式，而是一种架构模式**，更是一个**工程化考量和项目管理**的问题。在早些年的时候，Web化趋势还不是那么明显，JSP可以应付大多数的业务场景，但是随着整个社会信息化程度的加深，以及各种各样的服务都Web化以后，前端的页面开始变得复杂起来，**JSP这种前后端高耦合的技术**就不是那么的好用了。其本质的原因，是因为前端并没有像后端一样，工程化、模块化和可复用化的思维来做。所以项目管理者就开始对项目进行解耦。
把前端开发工作从后端中分离出来，让前端开发工程化、组件化。

- 前后端各负其责， 前端和后端都做自己擅长的事情，不互相依赖，只需要约定好接口，对应参数以及返回数据格式就可以
- 增强代码可维护性，降低维护成本，改善代码的质量
- 同一套后端程序代码，不用修改就可以用于Web界面、手机、平板等多种客户端

但是**前后端分离要根据自己的实际需求来做**，因为想做一个彻彻底底的前后端分离，不管你是人力成本、**开发成本**、工具成本还是什么部署成本呐，其实都是不小好的

#### uni-app

优点：1、**多端开发**，一套代码，多段多端运行，可以生成ios、安卓、微信小程序、支付宝小程序等。结合HBuilder（一款HTML5的Web开发工具）开发速度快。

​      2、**学习成本低**，uniapp封装的组件（丰富的插件）与微信小程序相似，并且基于vue.js，上手快。

缺点：完善性较差，uni-app问世的时间还比较短，坑多。

#### SpringBoot

Spring是一个**轻量级（在系统初始化的时候不用加载所有的服务，用户可以自己启动想要的服务）**的**控制反转（IoC)和面向切面（AOP）**的**容器 框架** 。spring是**一个IOC容器，用来管理Bean，使用依赖注入实现控制反转**，可以很方便的**整合各种框架**；提供**AOP机制**弥补OOP的代码重复问题、更方便将不同类不同方法中的共同处理抽取成切面、自动注入给方法执行，比如日志、异常、权限验证等 

springmvc是**spring对web框架的一个解决方案或设计理念**，提供了一个总的前端控制器DispatcherServlet ，用来接收请求，然后定义了一套路由策略（url到handle的映射）及适配执行handle，将handle结果使用视图解析技术生成视图展现给前端。

随着Spring 的发展逐渐变得笨重，产生大量繁琐的XML配置和第三⽅整合配置。springboot是spring提供的一个快速开发工具包，其实就是Spring，它做了一些对Spring Bean的默认配置。让程序员能更方便、更快速的开发spring+springmvc 应用，**简化了配置**（约定了默认配置）**，整合了一系列的解决方案**（starter机制）、redis、 mongodb、es，核心理念：开箱即用，快速启动

#### （1）xssFliter

> 注入恶意指令代码到网页，用户点击时会执行对应的指令代码
>
> 例如：攻击者利用XSS在网页中插入恶意脚本，一旦用户访问该网页，cookie就会自动地发送到攻击者的服务器中去。

为加强系统的安全性，**自定义xssFliter**对请求数据进行转义，抵御跨站脚本**XSS攻击**。

为了将数据中的html标签去除，需要对用户提交的数据进行转义。我们都知道Filter能在request到达servlet的服务方法之前**拦截HttpServletRequest对象**。但是HttpServletRequest中的**参数是无法改变**的，若是手动执行修改request中的参数，则会抛出异常。因此我们定义请求包装类MyXssHttpServletRequestWrapper 继承**HttpServletRequestWrapper**，这个类可以对HttpServletRequest**进行功能增强**。

1、导入依赖hutool（提供一些Utile工具类）
2、定义请求包装类MyXssHttpServletRequestWrapper 继承**HttpServletRequestWrapper**对数据进行转义
3、创建过滤器，将请求拦截并**使用自定义包装类覆盖原request**
4、主类添加@ServletComponentScan扫描过滤器(@WebFilter)

```java
  HttpServletRequest request= (HttpServletRequest) servletRequest;    //转HttpServletRequest
        MyXssHttpServletRequestWrapper  wrapper=new MyXssHttpServletRequestWrapper (request);
        filterChain.doFilter(wrapper,servletResponse);
```

#### **（2）Spring AOP+Shiro+**JWT⭐️

（1）为什么？

利用**Spring AOP+Shiro+**JWT**实现**用户鉴权和**RBAC模型的资源控制**

主要使用的 AOP去做权限认证，还有一些日志的操作，因为是将它可以定义一些切点，然后将那个切点的一些切面动态植入进去，很方便地去帮我们做一些权限的判断。比如说我们**用 jwt 然后进我们的系统之前可以先 AOP 拦截下来，然后去判断他这个权限，然后也可以去把我们的一些日志操作**。

> 比Spring Security更加广泛，不局限于Spring框架，使用更简单、灵活
>
> Shiro认证和授权：拦截请求，判断用户是否登录；登录了，再判断是非有权限访问该web方法
>
> 另外，shiro可以利用httpsession或者redis存储的用户信息保存凭证，通过认证授权的过滤器对每个http请求进行认证和授权
> 如果单体，shiro可以；如果用到负载均衡，单靠shiro不够。
> 用户登录负载均衡到tomacatA的httpsession上；用户发出下个请求，tomcatB可没有httpsession。而且session是基于cookie进行用户识别的, cookie如果被截获，**CSRF跨站伪造请求攻击**（*攻击*者诱导受害者进入第三方网站，在第三方网站中，向被*攻击*网站发送*跨站请求*。）CSRF攻击者不能获取到cookie，只能使用。浏览器会自动将cookie 放入请求头中传给后端，而token 并不会自动被浏览器放入请求头
>
> 于是引入JWT技术
>
> 原来登录凭证在服务端保存，现在将登录凭证加密后（Token）在客户端保存，每次请求都带上该凭证。
>
> 简单*token的组成*;uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign(签名,token的前几位以哈希算法压缩成的一定长度的十六进制字符串。为防止 token泄露) 

![image-20220218210830365](images/image-20220218210830365.png)

1）**支持跨域访问**: Cookie是不允许垮域访问的，token支持；

2）更适用于**移动应用**: **Cookie不支持手机端访问的**；**JWT兼容更多设备，后面还可以实现单点登录**

3）性能: 在网络传输的过程中，**性能更好**；

4）**无状态**： token无状态，session有状态的；

（2)实现过程

1、将token(JWT生成和验证)封装成认证对象（使用ThreadLocal保证线程安全）
![在这里插入图片描述](images/d1485c51c597477ca907edb3c0a6a85d.png)

> Context 类使用 String 变量 (static String USER_ID) 进行存储
>
> 用户 A 登录，带着自己的 token，到达后端拦截器，token 验证通过后，用户信息被提取到 Context 中的 String 变量中。
> 用户 B 登录，带着自己的 token，到达后端拦截器，token 验证通过后，用户信息被提取到 Context 中的 String 变量中。（这里 String 变量之前存储的是 A 的信息，但是由于 B 登录以后，又将 String 的值设置为了 B 的 token 中提取出来的用户信息。）
> 用户 A 调用新增的 api，这时候调用新增 api 的这个请求，也附带了 A 的 token 信息，所以重复第一步。
> 用户 B 调用新增的 api，这时候调用新增 api 的这个请求，也附带了 B 的 token 信息，所以重复第二步。
>
> A 刚设置了值，还没有等到 A 取值，B 就将这个 String 类型的 USER_ID 设置成了自己的信息。这时候 A 再进行取值，取到的就是 B 的值
>
> 原理：
>
> **每一个 Thread 对象均含有一个 ThreadLocalMap 类型的成员变量 threadLocals ，它存储本线程中所 有ThreadLocal对象及其对应的值** 
>
> **ThreadLocalMap** 由一个个 Entry 对象构成。一个 Entry 由 ThreadLocal 对象和 Object 构成，并且Entry 继承自 WeakReference<ThreadLocal<?>> 。由此可见， **Entry 的key是ThreadLocal对象，并且是一个弱引用。当没指向key的强引用后，该key就会被垃圾收集器回收。**
>
> 内存泄露：
>
> - 因此在**使用完ThreadLocal要手动调用remove()或使用拦截器调用remove()**，阿里规约
>
> - 将ThreadLocal变量定义成private static，这样就一直**存在ThreadLocal的强引用**，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。

2、定义认证与授权的实现方法（Realm类）
3、拦截HTTP请求，验证Token（Filter)，验证token合法性，判断是否过期，若客户端token过期，redis中的未过期则重新生成token，反之重新登录。

![- 验证token合法性，判断是否过期，若客户端token过期，redis中的未过期则重新生成token反之重新登录。](images/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zi75Zi75ZOI5ZOI5rKh5pyJ55uu5qCH,size_16,color_FFFFFF,t_70,g_se,x_16)

4、把设置应用到Shiro框架（创建ShiroConfig回传四个对象）
![在这里插入图片描述](images/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zi75Zi75ZOI5ZOI5rKh5pyJ55uu5qCH,size_20,color_FFFFFF,t_70,g_se,x_16)

5、 回传token：**使用AOP拦截Web方法返回值**，从ThreadLocalToken中获取token写入返回对象，然后返回。

> 即使两个线程同时执行这段代码，它们也无法访问到对方的ThreadLocal变量。

![在这里插入图片描述](images/d7dc188839324ee4a139912ecc7c9ae7.png)

> AOP中注解的含义
>
> @Aspect：切面。表示一个横切进业务的一个对象。它里面包含切入点(Pointcut)和Advice（通知）。
> @Pointcut：切入点。表示需要切入的位置，比如某些类或者某些方法，也就是先定一个范围。
> @Before：Advice（通知）的一种，切入点的方法体执行之前执行。
> @Around：Advice（通知）的一种，环绕切入点执行也就是把切入点包裹起来执行。
> @After：Advice（通知）的一种，在切入点正常运行结束后执行。
> @AfterReturning：Advice（通知）的一种，在切入点正常运行结束后执行，异常则不执行
> @AfterThrowing：Advice（通知）的一种，在切入点运行异常时执行。

![image-20220618175826277](C:/Users/Y7000P/Desktop/aa/image-20220618175826277.png)

![image-20220219215301940](images/image-20220219215301940.png)

##### **RBAC权限模型**⭐️

（1）概念

![image-20220219135355962](images/image-20220219135355962.png)

> 返回用户对应的权限列表，就可以根据权限列表判定用户可以看到什么页面。
>
> *简化了用户和权限的关系易扩展、易维护*
>
> 好处：管理员不用为不同用户勾选不同权限，只需要指定对应角色就可以了，减少工作量

（2）权限由来？

> 权限由来：(模块)USER：（行为）INSERT 添加员工 （权限）

![image-20220219135413609](E:/Java/images/image-20220219135413609.png)

![image-20220219134305165](images/image-20220219134305165.png)

![image-20220219134352935](images/image-20220219134352935.png)

![image-20220219134819271](images/image-20220219134819271.png)

（3）怎么将权限赋给角色？

> 通过字段permissions，JSON类型

![image-20220219135059758](images/image-20220219135059758.png)

****

（4）角色表关联用户表

> 通过字段role，JSON类型

（5）前后端权限验证

后端=>shiro

前端=>当前用户的权限列表【`登录成功`，`登录失败`】（后端返回）,移动端保存到Storage

#### （3）令牌的自动刷新

利用**ThreadLocal+Redis**实现令牌的自动刷新，降低令牌泄露的风险以及提高用户体验。

（1）背景：令牌不刷新可能会有泄露的风险，所以需要刷新；而且客户端的token也会存在过期时间，如果用户一直登录系统，过期也需要重新登录，这样用户的体验不太好。所以，就有了token自动刷新的机制。

（2）如何做？

- 双令牌机制

1. 设置长短日期的两个令牌，两个令牌都传给客户端，客户端每次携带两个令牌请求
2. 当两个令牌都没有过期的时候，服务端正常验证逻辑
3. 如果短令牌过期，长令牌没有过期，那么服务端重新生成两个新的令牌返回给客户端，客户端下次就带着新的令牌请求，完成了令牌的自动刷新。都过期那就重新登录。

> 长短令牌：服务端判断用哪个令牌；

- 缓存令牌机制

1. 服务端不仅将令牌返回给客户端，同时将令牌缓存到Redis中，缓存时间比客户端令牌的过期时间多一倍（客户端5天，服务端10天，因为5天之后过期，续期刚好多5天。）
2. 如果客户端令牌过期了，但是Redis中的没有过期，那么就生成一个新的令牌返回给客户端，完成自动的令牌续期
3. 如果两者都过期了，那么就让用户重新登录。

> redis：不需要（令牌相同，只是过期时间不同），逻辑肯定简单

**在响应中添加令牌**

![image-20220218220402790](images/image-20220218220402790.png)

![image-20220218223010723](images/image-20220218223010723.png)

为什么不把Token直接写入到`OAuth2filter`？

> 往响应写数据，需要借助IO流，比较复杂，而利用AOP拦截web方法返回的R对象，在往TheadLocalToken put数据，R返回给OAuth2filter，写入响应里面返回给客户端。（在AOP和拦截器传递Token，方便其他接口取到用户信息）
>
> **通过 ThreadLocal ，将其与当前线程绑定**。TheadLocalToken起到线程安全的作用，避免数据覆盖，同时避免重复传参。
>
> 怎么保证线程过多内存不会溢出呢？
>
>  答：在拦截器的**afterCompletion**方法中添加ThreadLocal线程删除方法，这样每次请求结束后会将ThreadLocal线程中的数据删除，这样保证了线程不会太多，内存不会溢出。
>
> 在[并发](https://so.csdn.net/so/search?q=并发&spm=1001.2101.3001.7020)请求情况下，因为每次请求都有不同的用户信息，我们必须保证每次请求保存的用户信息互不干扰，线程独立。注意：这里不是**解决多线程资源共享问题，而是要保证每个线程都有自己的用户资源，互不干扰**。
>
> ```java
> private static ThreadLocal<Map<String, Object>> cache = new ThreadLocal<Map<String, Object>>();
> ```

#### （4）人脸识别

利用开源项目：insightFace，用户注册人脸，上传图片到后端，并将图片数据存入到MQ（写入并持久化成功返回ack）中，再从MQ里面取数据，利用人脸识别模型，检测出人脸，提取人脸特征将数据（用户id），最终再将人脸特征的数据存入数据库后才返回ack；

然后人脸识别考勤的时候（看是否注册过人脸，没有的话先去注册），同样上传图片到后端，并将图片数据存入到MQ，利用人脸识别模型，检测出人脸，提取人脸特征，（会去数据库查看是否已经注册过）再和数据库中的人脸数据进比对（欧式距离），设置相似度（百分之80-90左右，太高的模型识别不出来）。超过时间签到按钮变灰。 （RTX1080Ti：10ms左右，最高100张/s  1G显卡，8卡 800张/s）

> 人脸表（id，用户id，姓名，编码后的人脸数据）
>
> 考勤表（id，用户id，签到日期，签到时间，签到地址，签到结果（-1缺勤，0正常，1迟到））
>
> 7:00-8:30签到时间 8:30-12:00还可以签到但是迟到，其他时间不可以签到
> 重复签到，去数据库查看当天是否签到过，否则可以签到
>
> 时间表（7:00开始，8:30，8:30-12:00）
>
> 工作日（），工作日调整为节假日
>
> 节假日（），节假日调整为作日
>
> 判断当前是否为工作日，并且是否考勤过，是否在考勤时间内，是的话才可以考勤。
>
> 行为表（）
>
> 模块表（）
>
> 权限表（）
>
> 角色表（）
>
> 用户表（）
>
> 
>
> 消息表（）
>
> 消息参考表（）



> （对于海量数据）为了加快检索速度，采用近似最近邻搜索算法（logn）（基于图，树，哈希：采用随机投影树，对所有的数据进行划分，将每次搜索与计算的点的数目减小到一个可接受的范围，然后建立多个随机投影树构成随机投影森林，将森林的综合结果作为最终结果。）ln（N）。同时，java代码层面使用的是线程池（16个线程负责1000个，每个线程返回top10，再聚合起来，从大到小排序。100ms左右加上检索+网络传输时间20ms=120ms，8.3 tps   	64*2=128
>
> id，姓名，512（685）维的人脸特征值如果在2GB的业务系统中，可以很轻松的保存10W+的人脸库数量。
> **一条记录大概4kb，100万需要大概4GB。**
> 留出一倍内存。比如你的redis数据占用了8G内存,那么你还需要再预留8G空闲内存。也就是内存需求是16G。内存占用率低于50%是最安全的。
>
> （1）单机Redis（最高并发量10万）
>
> （2）高并发：单机Redis主从架构（4个从节点：可以不抗20万并发量读，5万写并发）
>
> （3）海量数据：选择基于单机Redis集群模式来实现分布式特征检索方案
>
> Redis3.0加入了Redis的集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的master节点上面，从而解决了海量数据的存储问题。 Redis集群采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。
>
> 本系统数据库采用了读写分离、Redis 热缓存降低数据库压力；服务器采用了 Nginx 进行负载均衡和反向代理
> 机制来增加请求响应速度；使用RabbittMQ 消息队列进行削峰处理，降低服务器压力；静态资源使用 CDN 来加速资源的获取。
> 同时，使用了行业内认可的压力测试工具 Apache JMeter进行测试，测试结果良好，能够在合理的时间内完成系统的请求。
>
> 对请求接口进行测试，设置线程数为 100，超时时间设置为 1s，平均响应时间500ms左右

![image-20220220120109370](images/image-20220220120109370.png)

```java
//https://github.com/chengxy-nds/ArcSoftFaceDemo   
@Override
    public List<FaceUserInfo> compareFaceFeature(byte[] faceFeature, Integer groupId) throws InterruptedException, ExecutionException {
        List<FaceUserInfo> resultFaceInfoList = Lists.newLinkedList();//识别到的人脸列表

        FaceFeature targetFaceFeature = new FaceFeature();
        targetFaceFeature.setFeatureData(faceFeature);
        List<FaceUserInfo> faceInfoList = userFaceInfoMapper.getUserFaceInfoByGroupId(groupId); //从数据库中取出人脸库
        List<List<FaceUserInfo>> faceUserInfoPartList = Lists.partition(faceInfoList, 1000);//分成1000一组，多线程处理
        CompletionService<List<FaceUserInfo>> completionService = new ExecutorCompletionService(executorService);
        for (List<FaceUserInfo> part : faceUserInfoPartList) {
            completionService.submit(new CompareFaceTask(part, targetFaceFeature));
        }
        for (int i = 0; i < faceUserInfoPartList.size(); i++) {
            List<FaceUserInfo> faceUserInfoList = completionService.take().get();
            if (CollectionUtil.isNotEmpty(faceInfoList)) {
                resultFaceInfoList.addAll(faceUserInfoList);
            }
        }

        resultFaceInfoList.sort((h1, h2) -> h2.getSimilarValue().compareTo(h1.getSimilarValue()));//从大到小排序

        return resultFaceInfoList;
    }
```

#### （5）mongdb+RabbitMQ⭐️

**难点：发送全站消息通知以及实现已读未读功能**（考勤打卡通知，放假通知，人脸数据MQ）

（1）选择MongoDB和RabbitMQ理由

1. 对于公告消息，本设计是设计为 为每个用户创建一条公告信息（原因是：方便记录用户对于**消息的已读和未读状态**，这样设计会更符合用户需求），因此设计两个表，message(存储消息uuid及其发送者id，消息主体) 和 message_ref（消息接收者，消息uuid，已读和是否为最新状态）
2. 数据库选择为MongoDB，原因是MongoDB对于**海量数据以及高并发情况下的读写数据很有优势**(同时向n个用户发送m条消息则需要在数据表中记录m*n条数据，发送消息的瞬间将有大量的性能损耗在数据库读写上，此时传统的关系型数据库则会严重影响整个系统的运行)，同时他的数据存储是以**文档结构存储**，简单来说就是用JSON格式，他会更加类似关系型数据库的存储（**基于内存，将热数据存放在物理内存中，从而达到高速读写**），同时MongoDB从3.X开始支持**集合的连接查询**，就可以实现message和message_ref连接查询，**查询出某个用户拥有的消息**。
3. 由于存在海量数据，高并发情况下，MongoDB也支持不了瞬时写入百万数据，因此引入消息队列MQ来进行**削峰填谷**。选择RabbitMQ的原因是，它的可靠性和稳定性比较好，而且不仅支持消息的异步收发，还支持消息的同步收发。（其他调研（吞吐量，响应时间，可靠性，可用性，社区活跃度），重复消费，消息丢失，异步线程同步收发）

> RabbitMQ支持**同步和异步的消息收发，稳定性更强，有五种队列模式**

> 至于为什么MongoDB使用B树而不是B +树，可以从其设计的角度考虑它。  MongoDB不是传统的关系数据库，而是以BSON格式(可以认为是JSON)存储的**nosql**。
>
> Mysql是关系型数据库，最常用的是**数据遍历操作**(join)，而MongoDB它的数据不像Mysql那样表之间的关系那么强烈,因此MongoDB更多的是**单个查询**。
>
> 由于Mysql使用B+树，数据在叶节点上,叶子节点之间又通过**双向链表连接**,更加有利于数据遍历，
> 而MongoDB使用B树,所有节点都有一个数据字段。只要找到指定的索引，就可以对其进行访问。毫无疑问，**单个查询MongoDB平均查询速度比Mysql快**。
>
> B树查询时间复杂度不是固定的，它与键在树中的位置有关，最好是O(1),可能第一层就搜索完了

（2）**收发消息的实现逻辑**（）

1、生产者：发送系统通知（放假通知）时，先把消息数据插入mongoDB的**message**表中，同时把消息推送到相关的消息队列（以用户id作为topic）中去；同时**开启confirm模式**（异步，推荐），写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。

2、消息队列**开启持久化**这样可以防止消息丢失，配合confirm模式，只有消息被持久化到磁盘之后，才会通知生产者ack了

3、消费者消费消息时，**取消自动ACK**，把数据插入mongodb的**message_ref**（lastFlag为true【新信息】，readFlag为false【未读】）中，**插入成功后再发送消息的Ack**应答，如果想要删除这条消息，附带一个**deliverTag标志位**就可以了。

4、小程序端设计定时器，每5分钟轮询从消息队列中接收消息（有了uuid）并从mongdb查询有多少条最新和未读消息，然后把message_ref中的lastFlag更新为false，更新的数量即为新消息的数量。用户点击消息，发送ajax将该消息未读修改为已读。

> 针对重复消费，每条MQ消息都有UUID值（唯一索引）

3.1五种队列模式

1）简单模式：一对一

2）Work模式：一个生产者对应多个消费者，但只有一个消费者能获得消息，**具有排他性**

3）发布订阅模式：Work的改进，**fanout交换器**，所有消费者可以接收消息

4）路由模式：**direct交换器**，按照key路由，符合规则才会转发到该队列

5）主题模式：生产者将消息发送到**topic交换器**，交换器按照复杂的规则将消息路由到某个队列

> topic就是（用户id+""）

![image-20220820094545981](images/image-20220820094545981.png)

针对**重复消费**：小程序每个5分钟进行轮询，如果积压得消息太多，Java系统没有接受完消息，这时候新的轮询到来，就会产生两个消费者共同接收同一个消息的情况，数据库就添加了同样的记录，如果每条MQ消息都有UUID值（唯一索引），第一个消费者把消息保存到数据库后，第二个消费者就无法继续保存了。

> 注册：默认系统id=0给用户id（topic）发送消息，保存到mongdb的message

![image-20220820094725077](images/image-20220820094725077.png)

> 离线过程中，消息通知保存在MQ中，用户登录后，就让MessageTask异执行接收MQ消息，然后存储到MessageRef
>
> 每5分钟，轮询接收系统消息。
> 用户点击消息，发送ajax将该消息未读修改为已读

<img src="images/image-20220820101055485.png" alt="image-20220820101055485" style="zoom:50%;" />

![image-20220820105558119](images/image-20220820105558119.png)

> 如果收发消息的时候我们的**Java代码**选择了同步执行，当用户登录的时候消息没有接收完成，那么Java代码就不会继续往下执行，会造成等待事件过长。如果选择**异步执行**，收发消息是挂载在后台的，让一个线程去执行。
>
> RabbitMQ提供了同步和异步两种收发消息模式，如果选择了异步，则需**要创建一个消费者对象挂载在后台去运行，消费者对象不会退出**，没有消息则处于等待状态，而且消费者对象只接收某个用户的消息，例如有一万人登录系统，则会创建一万个消费对象，这对操作系统虚拟机要求很高。同步收发消息，消费者对象销毁这才是可取的。所以我们可以采用**异步线程同步收发消息**。

#### （6）线程池

使用**线程池**异步发送邮件和消息，提高系统**响应速度**同时降低资源消耗

```java
// 设置核心线程数
executor.setCorePoolSize(16);
// 设置最大线程数
executor.setMaxPoolSize(16);
// 设置队列容量
executor.setQueueCapacity(32);	//防止OOM
// 设置线程活跃时间（秒）
executor.setKeepAliveSeconds(60);
// 设置默认线程名称
executor.setThreadNamePrefix("task-");
// 设置拒绝策略CallerRunsPolicy，谁提交谁处理
```

![image-20211231210225294](images/image-20211231210225294.png)

```
（1）线程数 < corePoolSize，即使其他工作线程空闲，也会创建一个新线程来运行新任务。
（2）线程数>=corePoolSize，<maxPoolSize，将任务放入workQueue中（希望保持较少的线程数）
（3）工作队列已满，线程数<maxPoolSize，则创建1个新线程
（4）队列已满，线程数>=maxPoolSize，拒绝该任务。
```

### **可迁移场景下的数字文档管理系统**

#### （1）全文检索

1）**Elasticsearch** 实现**全文检索**（FST存倒排索引）

 Elasticsearch 是基于 **Lucene** 的 Restful 的**分布式近实时**全文搜索引擎。
采用的倒排索引技术实现数据的快速检索；

存储的数据采用的是**分片**机制（**分布式，并行，做到高性能/高吞吐量**）；副本机制为了高可用，主，副分片不在同一个节点上（避免点挂掉了）

 ES 扩展性很好，我们可以通过**水平扩展**的方式去增加服务器来提升 ES 的处理性

> ES 并不是万能的，如果使用不恰当，也会带来一些性能的瓶颈。比如说 ES 里面我们不建议去使用**复杂的关联查询**，这个对性能影响很大，（所以我们事先处理好要查询的数据，再写入ES）。第二个，避免深度分页查询。因为 ES 的分页是支持 from 和 size 参数。在查询的时候，每个分片必须要去**先构造一个长度为 from 加 size 的优先队列**，然后回传到协调节点再对这些优先队列进行排序，再找到正确的 size 个文档。而当 from 足够大的情况下，容易造成 OOM 以及网络传输性能差的一些问题。

2）倒排索引理解（与正排索引），创建，检索过程。

> 词项-索引（FST与前缀树），词项-字典，倒排表（FOR压缩）

3）写数据过程（底层原理refresh，flush），查数据过程（读负载均衡），搜索过程

4）分片机制：

> 7.x之前创建索引默认：5个主分片，现在1个主分片

每个shard都有**一个primary shard（读写）**，负责写入数据，但是还有**几个replica shard（读）**。primary shard写入数据之后，会将数据同步到其他几个replica shard上去。某个机器宕机了，还有数据副本在别的机器上，高可用。

#### （2）智能提示

**IK 分词器+Completion Suggester** 实现搜索智能提示

标准分词器：会把每一字都分出来，一个个字显然不太合理，小写处理

Simple Analyzer：按照非字母切分（符号被过滤），小写处理

Stop Analyzer：停用词过滤（the，a，is），小写处理

Whitespace Analyzer：按照空格切分，不转小写

IK 分词器：基于正向匹配的分词算法

```
1、IK分词器，基本可分为两种模式，一种为smart模式，一种为非smart模式
2、非smart模式所做的就是将能够分出来的词全部输出；smart模式下，IK分词器则会根据内在方法输出一个认为最合理的分词结果，这就涉及到了歧义判断
张三 | 说的 | 确实 | 在理

1）词典：词典的好坏直接影响分词结果的好坏（停用词），有了词典之后，就可以对输入的字符串逐字句和词典进行匹配
2）消除歧义：通过词典匹配出来的切分方式会有多种，消除歧义就是从中寻找最合理的一种方式

规则1: 比较有效文本长度
规则2: //比较词元个数，越少越好
规则3: //词元路径跨度越大越好
规则5: //词长越平均越好(词元长度相乘)
规则6: //词元位置权重比较(词元长度积),含义是选取长的词元位置在后的集合
```

**智能提示**

- **Completion Suggester** 提供了“自动完成（Auto Completion）”的功能，用户每输入一个字符，就需要**即时发送一个查询**请求到后端查找匹配项；

- 这种功能对性能的要求比较苛刻，ElasticSearch 采用了不同的数据结构，而**不是使用倒排索引**来实现；通过将 Analyzer 的数据编码成 **FST 和索引**一起存放；FST 会被 ES 整个加载进**内存**，从而达到更高的性能；

- FST （有限状态转移机）只能用于**前缀查找**；

> lucene3使用跳跃表来存储词典，lucene4使用FST来存放词典。
>
> 1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；
> 2）查询速度快。**O(len(str))**的查询时间复杂度。
>
> 有限状态机顾明思议就是全部状态可以全部被列举出来，然后随着不同的操作在不同的状态之间转换。

![image-20220819153429427](images/image-20220819153429427.png)

排序列表：二分查找，不平衡

hashmap：：**占用空间大**

前缀树（适合英文）

- 没有解决后缀共用问题，**只解决了前缀共用**（这也是字典树又被称之为前缀树的原因）。当数据量达到一定级别的时候，只共享前缀不共享后缀也会带来很多空间的浪费

B树  mongdb，检索慢；

B+树 mysql

- **全文索引的文本字段通常会比较长**，索引值本身会占用较大空间，从而会加大 `B+` 树的深度，影响查询效率。
- 全文索引往往需要全文搜索，不遵循最左匹配原则，使用 `B+` 树可能导致索引失效。

跳跃表：内存小，但对模糊查询支持不好



FST：O(len(str))

**使用步骤**

- 定义 Mapping，将字段的 type 设置成 completion；
- 索引数据（全量，预热）进 ES；
- 运行 suggest 查询，得到搜索建议；（此时返回结果集hist为空，只有suggest有返回数据）

![image-20220819110224611](C:/Users/Y7000P/Desktop/aa/image-20220819110224611.png)

#### （3）**Milus 图片检索**

Milvus 首先不是一个关系型数据库，不会支持特别复杂的 JOIN 之类的查询，也不会支持 ACID 的事务

Milvus 不是一个搜索引擎，跟传统的 Elasticsearch、Solr 之间也有很大区别。

Milvus 向量数据库专为**由非结构化数据转换而来的 Embedding 向量**的查询与检索设计，而不是传统的文本格式的数据，能够为万亿级向量数据建立索引，拥有**动态数据管理功能**，实时对数据进行插入、删除、搜索等操作。建议使用k8s部署

**好处**

- 高性能：性能高超，可对海量数据集进行向量相似度检索（**近似最近邻搜索算法**）。
- 高可用、高可靠：Milvus 支持在云上扩展，其容灾能力能够保证服务高可用。
- 开发者友好：支持多语言（java，python）。
- 增量更新

> 之前，自己使用annoy算法生成索引文件，但是如何有新的数据来，索引文件又得重新生成

对于文本来说，Milvus 做的是基于语义的检索，而不是基于关键词的检索。
对于图片来说，Milvus 做的是基于视觉特征的检索，而不是基于关键词的检索。

```
文本检索：上游：BERT； 下游：mysql
问答系统：上游：BERT； 下游：mysql
推荐系统(电影特征抽取)：上游：PaddlePaddle； 下游：redis或者mysql
图片检索：上游：ResNet-50； 下游：mysql
视频推荐：上游：OpenCV抽取视频关键帧，ResNet-50图片特征向量抽取；下游：Mysql，OSS
```

**近似最近邻搜索算法**

最近k近邻搜索，太慢了，得与所有数据进行比较

> 相似度：欧式距离，预先相似度

- 基于树：Annoy 

通过建立一个二叉树来使得每个点查找时间复杂度是O(log n)

建立过程：

annoy的每一次空间划分，可以看作聚类数为2的KMeans过程。收敛后在产生的两个聚类中心连线之间建立一条垂线（图中的黑线），把数据空间划分为两部分。
在划分的子空间内不停的递归迭代继续划分，直到**每个子空间最多只剩下K个数据节点**，划分结束。

查询过程：

1. 将每一颗树的根节点插入优先队列; 
2. 搜索优先队列中的每一颗二叉树,每一颗二叉树都可以得到最多 Top K 的候选集
3. 删除重复的候选集; 
4.  计算候选集与查询点的相似度或者距离;
5. 返回top k 集合

影响 annoy 算法效率和精度的重要参数：

**n_trees**：表示树的棵数，会影响构建索引的时间（不影响搜索时间）。值越大表示最终的精度越高，但是会有更多的索引；

**search_k**：值越大表示搜索耗时越长，搜索的精度越高；

> n_trees = 100， 向量维度1000，欧式距离 search_k=10，精度可以达到99%以上

- 基于图的索引量化法：HNSW（类似跳表）

HNSW采用类似跳表的思想，在高层跳过大量离目标点较远的点，从而快速定位到离目标较近的点，从而缩小搜索范围。

建立过程：

是通过贪心算法遍历图，找出当前数据集中的最近邻点（局部最小值），以此作为插入并构建生成层状网络图，通过在下一层中不断寻找最近邻点插入构建，从而完成对特征向量集的维度分层、数据压缩、索引生成。（第0层包含所有的数据，level1的顶点是level0的子集，是从level0的节点里随机采样的，level2是level1的子集，每个向量和与它距离最近的P个向量对应的顶点连接成边）

检索过程：

检索时，采用自上而下的搜索方式，即从最顶层开始粗略搜索，然后逐步向下层搜索，直到最底层精确搜索。

缺点：HNSW算法在查询速度和精度上优于其他算法，但是占用内存大

- 基于哈希：SLH

局部敏感：空间中距离较近的点映射后发生冲突的概率高，空间中距离较远的点映射后发生冲突的概率低。

查询过程：

计算q在每张哈希表的哈希值，取出对应哈希值的哈 希桶内所有点，与q做距离计算。

缺点：生成索引编码的结果并不稳定（哈希表的设计），查询准确率不高
用神经网络创建的哈希替换现有的 LSH 技术



### 中广核的软件验证项目

难点：识别速度上。

燃料组件检测识别，视频流要求实时检测，Tensorert加速，int8，int16，单精度float32；**4 倍**
卡顿，线程+queue的方式，跳帧；opencv底层是cap = cv2.VideoCapture(0)，cap.read()读取图片到缓存中，如果处理速度跟不上读取的速度，缓冲区会溢出，导致程序奔溃。

抓拍时机：

考虑运动过程中抓拍的图片可能会模糊，不好识别，同时我们又不能实时地去进行文字检测和识别，这样速度是很慢。摄像头抓燃料组件，通过后台线程实时判断当前帧和前3s的帧的直方图的相似性，达到98，表明当前是静止的，此时我们就可以抓拍图片进行识别。

预处理：检测整个大框，再检测螺母，定位到哪个字符区域，再利角点检测矫正，分割文本行，识别速度和精度都大大提升。**15%**，后处理的话，针对识别的结果进行一些，规则的约束（比如：我们字符里面只识别只有字符1，没有i，只有0没有O，如果识别成i，或者O就将其纠正为1,0；目前很难识别）

图像分类：**5%**以上

resnet，引入注意力机制的resnet。*分类投票法*:预测结果是所有*模型种*出现最多的预测结果。

没有的话就取置信度最高的作为识别结果。（置信度：认为属于某个类别的可性程度）





### 莞工教学助手

#### 介绍

因为老师和学校需要登录不同系统是查看信息，不方便；特别是教师，如果在校外就查看不了作业，而且统计作业提交情况很繁琐，还有上课忘带学生名单；而学生上课可能忘记课室，而且不知道自己学了多少个学分。

#### （1）中文乱码

1. 通过先检测服务器编码格式，再统一编码的方法**解决中文乱码问题**

   > 要理解乱码，首先需要知道计算机是如何储存文字的，计算机只能储存 0 和 1 这些二进制数字。无论是我们**文本里的数字字母、汉字、emoji都需要用某种方式转换成二进制数字进行储存**，需要的时候再读出来。 比如用GBK的编码的编辑器写了一个文档发给另外一个人，另外一个人用Big5的编辑器打开就会看到乱码。
   >
   > **ascii**单字节编码，适用于 128 个字符。虽然英文文本 OK 但其他语言就不够用了，比如法语带音符的字母、中文汉字、日文片假名等都统统表示不了。于是不同国家和地区开始制定自己的编码标准。比如我们中国的 **GB 2312（简体），港澳台的Big5（繁体），后来还有对 GB2312 进行扩展的 GBK** （收录了简繁体汉字、日文、韩文等）。但标准不统一时，乱码问题也随之产生。因为计算机内存里的同一个数字，在不同字符集里代表的可能是完全不同的字符。于是大家急需一种更通用的字符编码，支持不同语言的文字。
   >
   > 于是出现了**unicode字符编码**（真正是字符映射到计算机存储内容的映射，比如一个表情字符的码点为12000，在计算机存储12000的二进制内容）。 unicode 如今已经囊括了 10 万多个字符，存在的问题unicode就是单个字符需要的储存空间更大。因此 UTF 32 让每个字符都以 32 bit 即 4 字节的长度来储存，但让英文使用者有点不爽。
   > ascii 编码的每个英文字母只要 1 字节，现在 UTF 32 要 4 字节，这相当于相同内容的英文文本。 GBK 里一个汉字只占俩字节，相当于用 UTF 32 的话空间会多占一倍。为了改善空间效率，拯救字符苍生的 UTF 8 在 1992 年诞生。**UTF 8 是针对 unicode 的可变长度编码**，不同于编码后长度固定为 32 bit 的 UTF 32。 UTF 8 针对不同字符，编码后的长度可以是 32 bit 24 bit 16 bit 8 bit 具体规则是，码点在 0 到 127 范围的字符直接映射为 1 字节长度的二进制数；码点在 128 到 2047 范围的字符映射为 2 字节的二进制数。（**ISO 8859-1是一个单字节编码，可以代表前256个Unicode字符，iso-8859-1是不支持中文的**）
   >
   > UTF 8 为了解决我们之前提到的计算机需要能够知道各个字符之间到底在哪里分割，就让 **2 字节编码的第一个字节由 110 开头**，表示自己及后面一个字节是一起的，都在表示同一个字符。然后**第二个字节由 10** 开头，unicode的二进制码点会被分割为两个部分，填入 UTF 8 编码的数字里。
   >
   > UTF 8 第一个好处是兼容 ascii unicode；第二个好处是节约空间。
   >
   > “锟斤拷”一般在 UTF 8 和中文编码比如和 GBK的转换过程中产生。 unicode 字符集有一个特殊的替换符号，专门用于表示无法识别或展示的字符。而在 UTF 8 编码后是这个 3 字节长度的二进制 efbfbd efbfbd ，而efbf bdef bfbd 如果这个时候把文件再用 GBK编码读取就是锟斤拷

   ```java
   name=new String(name.getBytes("GBK"),"iso-8859-1");
   (2)客户端是GBK，ftp服务器（默认GBk）中的设置就已经是utf-8的编码，所以肯定还是会出现乱码的问题。
       它向服务器发送了OPTS UTF8 ON命令，来开启服务器对UTF-8的支持
       如果服务器支持UTF-8我们就用UTTF-8，否则我们就用本地编码（GBK）来处理中文文件名。
   
   private static String LOCAL_CHARSET = "GBK"; //看服务器是否支持UTF8
   private static String SERVER_CHARSET = "ISO-8859-1";
   fileName = new String(fileName.getBytes(LOCAL_CHARSET),SERVER_CHARSET);
   
   //上传中文文件名
   ```

   ```java
   //（1）http请求参数中文乱码问题
   //方法1
   String userName = new String(userName.getBytes("ISO-8859-1"), "UTF-8");
   
   
   //方法2
   //1）指定请求数据的字符集为 utf-8 格式
   //2）通过 @RequestMapping 中的 produces 属性解决，指定接收方的响应数据字符集为 utf-8
   
   //数据库 昵称emoji表情包乱码，或者评论
   UTF-8是使用1~4个字节，一种变长的编码格式，字符编码。mb4即 most bytes 4，使用4个字节来表示完整的UTF-8。
   mysql的 utf8 编码最大字符长度为 3 字节，如果遇到 4 字节的宽字符就会插入异常了。所以推荐使用utf8mb4
   MySQL在5.5.3之后增加了这个utf8mb4的编码
   //1.保存前使用emoji的官方jar包提供的方法将表情转成代码，再保存
   //2.设置数据库的字符编码为支持emoji表情的字符集:utf8mb4
   //3.降级，不允许插入emoji
   ```


####   （2）模拟登录

利用（Requests库）爬虫技术**模拟登录**（非暴力入侵），**自动爬取**教务处上的信息，例如：成绩，课表等

突破登录限制：第一步需要进行网页调试，找登录的链接；然后将用户名，密码，post请求下，返回成功登录；但是此时我去请求登录后的一些页面失败，说是登录失败；后面，我再去网页调试（请求是顺序的），发现登录请求成功后，还需要再请求一个页面，它的这个页面是获取登录后的cookie，于是，我将获得Cookie放到请求头里，再次请求可是还是失败；于是我再次去看了下实际的请求，发现post请求header里面加入了参数Referer，最终成功了。

（3）Jsoup

3. 使用**Jsoup**解析页面数据，存入数据库中并**集成JSON API**，为小程序提供数据来源

Jsoup是一款*Java* 的HTML解析器，可直接解析某个URL地址、HTML文本内容。可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。

```java
Document doc = Jsoup.parse(html);
Elements links = doc.select("a[href]"); // 具有href 属性的链接
Elements pngs = doc.select("img[src$=.png]");//所有引用png图片的元素
Element masthead =doc.select("div.masthead").first();
```

存入数据库后，将每一个功能封装成一个个接口，比如：将成绩数据爬取下来，进行结构化处理，然后封装一个成绩查询的接口也就是我们的JSON API。

#### 	（4）Ngrok

4. 使用Ngrok实现**内网渗透**，访问内网的FTP服务器，**解决外网无法访问内网**的难题

> 内网主机搭建一个ngrok客户端（只转发请求）<=>公网ngrok服务端通信<=>客户端，ngrok客户端要和服务端建立http连接
>
> 这样子我们内网程序的服务就可以通过ngrok暴露给公网

#### 	（5）动态IP代理

5. 利用**动态IP代理**技术，解决因频繁访问校园服务器导致腾讯云**服务器IP被封**的问题

动态代理IP，市面上有付费的，不过比较贵。所以我自己搭建了一个代理IP池。
首先，去一个免费的IP代理网站，去爬取那些响应速度快的IP，并测试下能否访问目标服务器，可以的话加入IP代理池；有了这些IP之后，我就可以设置对应的IP去请求我们的目标网址。那怎么请求呢？

请求策略：

- 首先从IP代理池随机分配一个IP，然后根据IP的请求次数来判断是否需要更换代理，如果该IP请求次数超过30次，那就删除该IP，继续更换代理IP。
- 如果该IP已经到达过期时间，1800秒+随机一个50到200秒，也进行同样操作。
- 如果在请求的时候，发生异常或者超时我们也更改代理IP。
- 最后，IP代理池空了就更新整个IP代理池。

（6）项目部署

6. 将项目**部署到腾讯云服务器**，买服务器，注册域名，把域名填在微信小程序合法的域名列表里面，并在微信小程序上**发布上线**，该项目获得中国大学生计算机设计大赛国赛二等奖

> 在服务器搭建环境，部署好项目，然后需要进行域名的备案，再将域名填写到微信小程序的请求域名里面，最后还需要将小程序提交审核，才能上线。

### 2021软件精英挑战赛



### 2022软件精英挑战赛

