##### B+树和红黑树

​        [红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)和一般的[平衡二叉树](https://www.nowcoder.com/jump/super-jump/word?word=平衡二叉树)，增、删、改、查的过程和效率、时间复杂度      

​       https://www.cnblogs.com/ArleneZhangfj/articles/10067570.html      

md5哈希函数

```
MD5信息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。
```

```
简述一下vector内存机制？（不够扩充两倍）
map的实现？（红黑树）
unondered_map的实现？（哈希）
哈希碰撞了怎么办？
（开放寻址法
1.1. di=1,2,3，…，m-1，称线性探测再散列；
1.2. di=1^2,-1^2,2^2,-2^2，⑶^2，…，±（k)^2,(k<=m/2）称二次探测再散列；
1.3. di=伪随机数序列，称伪随机探测再散列
、再哈希、
链式）
```

哈希表

```
它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。
这个映射函数叫做散列函数，存放记录的数组叫做散列表
```

哈希表和平衡二叉树的适用场合

```
哈希表：哈希表查找速度比较快，但是要耗比较多的内存。所以比较适用于对查找速度要求比较高、且内存空间足够的时候
，数据元素之间无逻辑关系要求的情况。
平衡二叉树：如果想在以后用二分法查找的时候查找速度比较快的话用建立平衡二叉树的方法（）
```

树中节点查找过程

```
（递进的方式简述每种树的概念和思想 二分查找 -> 折半二叉树 -> 平衡二叉树 -> 红黑树 -> B/B+树）

```

```
一致性哈希（环输出域）
其中一个节点挂了怎么做（扔给下一个） 
如何实现负载均衡（每个机器无限多  id再hash）
```

哈希表大小设置多少合理 

```
（和vector一样吧，动态调整大小）

如果不考虑rehash怎么做（应该是质数，因为避免冲突，另外大小设置和输入数据有关，具体应该是查表，表是科学家实践得出的参考值）
```

红黑树比平衡二叉树和好在哪儿

```
牺牲部分平衡性，换来时间复杂度的优化
```

空间时间互换

```
时间换空间的典型应用是查表，比如我要你求出100以内所有的质数并输出，你可能会动态求出这些质数，
但是更快的是先求出这些质数并存到一个数组里面，然后直接输出这个数组即可。这就是空间换时间。
```

### 线性表



#### 数组VS链表

数组是一段连续的存储空间；链表不要求连续

数组支持随机访问，而链表不支持。

数组的大小固定，而链表则天然支持动态扩容。

需要经常添加和删除数据的话，使用链表比较合适。

#### 跳表



#### 十字链表



### 栈与队列

**栈和队列的区别**

队列：先进先出 
栈：先进后出 

队列和栈的遍历数据速度 
队列：基于地址指针进行遍历，而且可以从头部或者尾部进行遍历，但不能同时遍历，无需开辟空间，因为在遍历的过程中不影响数据结构，所以遍历速度要快 
栈：只能从顶部取数据，也就是说最先进入栈底的，需要遍历整个栈才能取出来，遍历数据时需要微数据开辟临时空间，保持数据在遍历前的一致性





**应用场景**

逆序输出（将一个非负的十进制整数N转换成其他D进制数），括号匹配，迷宫求解，二叉树遍历，表达式求值

回文判断：利用队列和栈的特性，一个是先进先出，一个是先进后出，迷宫问题，广度优先遍历

### 树与二叉树

##### 1.树

树转二叉树

```
左孩子右兄弟
//连接兄弟节点，砍掉非第一个左孩子，左旋45度
```

二叉树转树（二叉树有右孩子则转换为森林）

```
y是x的双亲 则将x的右孩子,x的右右孩子...与y连接，
砍掉兄弟的连接，以及双亲y的右孩子
```

树 森林的遍历

```
森林的先序遍历和中序遍历分别对应该树转换成的二叉树的先序遍历和中序遍历  森林无后序遍历的定
树的先序遍历和后序遍历分别对应该树转换成的二叉树的先序遍历和中序遍历    树没有中序遍历的定义。
```



##### 2.二叉树基本概念

##### 3.二叉查找树

##### 4.平衡二叉树

```
左右子树都是平衡二叉树 且左右子树的深度差值的绝对值不大于1。


```



##### 5.红黑树

### 图



```
前序，中序，后序都可以看作是DFS，用栈实现，因为他们都是在找到叶子节点前一直遍历。 
层序遍历属于BFS，用堆实现，因为它们是一层一层遍历。
```



```
https://www.nowcoder.com/discuss/346845?order=0&page=1&pos=6&type=0
面试常见智力题和概率题目及部分答案

1.在一个公交车站等公交车，等一分钟等到车的概率为p，那么等三分钟等到车的概率是多少（p+(1-p)p+(1-p)(1-p)p，典型的二分概率）

```



### 哈希表

```
不论哈希表中数据有多少，增加，删除，改写数据的复杂度平均都是O(1)，效率非常高
哈希表原理:根据关键码值(Key value)而直接进行访问的数据结构。

解决哈希冲突
1.开放定址法
    线性探测再散列		缺点：集聚
    二次探测再散列
    伪随机探测再散列

2.再哈希法

3.链地址法

https://www.cnblogs.com/hunternet/p/11324945.html


STL中hash_map扩容发生什么？
(1) 创建一个新桶，该桶是原来桶两倍大最接近的质数(判断n是不是质数的方法：用n除2到sqrt(n)sqrt(n)范围内的数) ；
(2) 将原来桶里的数通过指针的转换，插入到新桶中(注意STL这里做的很精细，没有直接将数据从旧桶遍历拷贝数据插入到新桶，而是通过指针转换)
(3) 通过swap函数将新桶和旧桶交换，销毁新
```

#### 堆排序

```
https://www.cnblogs.com/tong-yuan/p/Heap.html
https://blog.csdn.net/Answer2333333/article/details/100988379
堆排序的原理、怎么建堆和排序。
```

#### 快排

快速排序=冒泡+分治+递归

- 先从数量中取出一个数作为基准数（简单起见可以取第一个数）
- 分区过程，将比这个数大的数全放到他的右边，小于或者等于他的数放到左边（分区）
- 再对左右区间重复第一步、第二步，直到各区间只有一个数.（递归）

```
（快排原理是二分法，已经排序好序列复杂度最高，partion函数使用随机定位）
快排的最坏时间复杂度O（N2） 如何避免？（随机寻找pivot）如何随机
（基础库的随机函数，如果rand() 是 (0, 1)区间，修改区间大小和偏移）
```

#### 桶排序

- 设置一个定量的数组当作空桶； 
- 遍历输入数据，并且把数据一个一个放到对应的桶里去； 
- 对每个不是空的桶进行[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)； 
- 从不是空的桶里把排好序的数据拼接起来。  

#### 基数排序



#### 计数排序



#### 时间复杂度

![在这里插入图片描述](/Users/zcz/Desktop/images/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkwNzMzMg==,size_16,color_FFFFFF,t_70.png)

| 排序算法                                                     | 平均时间复杂度 | 最差时间复杂度          | 空间复杂度 | 数据对象稳定性       |
| ------------------------------------------------------------ | -------------- | ----------------------- | ---------- | -------------------- |
| [冒泡排序](https://github.com/huihut/interview/blob/master/Algorithm/BubbleSort.h) | O(n2)          | O(n2)                   | O(1)       | 稳定                 |
| [选择排序](https://github.com/huihut/interview/blob/master/Algorithm/SelectionSort.h) | O(n2)          | O(n2)                   | O(1)       | 数组不稳定、链表稳定 |
| [插入排序](https://github.com/huihut/interview/blob/master/Algorithm/InsertSort.h) | O(n2)          | O(n2)                   | O(1)       | 稳定                 |
| [快速排序](https://github.com/huihut/interview/blob/master/Algorithm/QuickSort.h) | O(n*log2n)     | O(n2)和直接插入排序一样 | O(log2n)   | 不稳定               |
| [堆排序](https://github.com/huihut/interview/blob/master/Algorithm/HeapSort.cpp) | O(n*log2n)     | O(n*log2n)              | O(1)       | 不稳定               |
| [归并排序](https://github.com/huihut/interview/blob/master/Algorithm/MergeSort.h) | O(n*log2n)     | O(n*log2n)              | **O(n)**   | 稳定                 |
| [希尔排序](https://github.com/huihut/interview/blob/master/Algorithm/ShellSort.h) | O(n*log2n)     | O(n2)                   | O(1)       | 不稳定               |
| [计数排序](https://github.com/huihut/interview/blob/master/Algorithm/CountSort.cpp) | O(n+m)         | O(n+m)                  | O(n+m)     | 稳定                 |
| [桶排序](https://github.com/huihut/interview/blob/master/Algorithm/BucketSort.cpp) | O(n)           | O(n)                    | O(m)       | 稳定                 |
| [基数排序](https://github.com/huihut/interview/blob/master/Algorithm/RadixSort.h) | O(k*n)         | O(n2)                   |            | 稳定                 |

| 查找算法                                                     | 平均时间复杂度   | 空间复杂度 | 查找条件   |
| ------------------------------------------------------------ | ---------------- | ---------- | ---------- |
| [顺序查找](https://github.com/huihut/interview/blob/master/Algorithm/SequentialSearch.h) | O(n)             | O(1)       | 无序或有序 |
| [二分查找（折半查找）](https://github.com/huihut/interview/blob/master/Algorithm/BinarySearch.h) | O(log2n)         | O(1)       | 有序       |
| [插值查找](https://github.com/huihut/interview/blob/master/Algorithm/InsertionSearch.h) | O(log2(log2n))   | O(1)       | 有序       |
| [斐波那契查找](https://github.com/huihut/interview/blob/master/Algorithm/FibonacciSearch.cpp) | O(log2n)         | O(1)       | 有序       |
| [哈希查找](https://github.com/huihut/interview/blob/master/DataStructure/HashTable.cpp) | O(1)             | O(n)       | 无序或有序 |
| [二叉查找树（二叉搜索树查找）](https://github.com/huihut/interview/blob/master/Algorithm/BSTSearch.h) | O(log2n)         |            |            |
| [红黑树](https://github.com/huihut/interview/blob/master/DataStructure/RedBlackTree.cpp) | O(log2n)         |            |            |
| 2-3树                                                        | O(log2n - log3n) |            |            |
| B树/B+树                                                     | O(log2n)         |            |            |

| 图搜索算法                                                   | 数据结构          | 遍历时间复杂度           | 空间复杂度               |
| ------------------------------------------------------------ | ----------------- | ------------------------ | ------------------------ |
| [BFS广度优先搜索](https://zh.wikipedia.org/wiki/广度优先搜索) | 邻接矩阵 邻接链表 | O(\|v\|2) O(\|v\|+\|E\|) | O(\|v\|2) O(\|v\|+\|E\|) |
| [DFS深度优先搜索](https://zh.wikipedia.org/wiki/深度优先搜索) | 邻接矩阵 邻接链表 | O(\|v\|2) O(\|v\|+\|E\|) | O(\|v\|2) O(\|v\|+\|E\|) |

#### 其他算法

| 算法                                               | 思想                                                         | 应用                                                         |
| -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| [分治法](https://zh.wikipedia.org/wiki/分治法)     | 把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并 | [循环赛日程安排问题](https://github.com/huihut/interview/tree/master/Problems/RoundRobinProblem)、排序算法（快速排序、归并排序） |
| [动态规划](https://zh.wikipedia.org/wiki/动态规划) | 通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法，适用于有重叠子问题和最优子结构性质的问题 | [背包问题](https://github.com/huihut/interview/tree/master/Problems/KnapsackProblem)、斐波那契数列 |
| [贪心法](https://zh.wikipedia.org/wiki/贪心法)     | 一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法 | 旅行推销员问题（最短路径问题）、最小生成树、哈夫曼编码       |





## 1.排序算法

![image-20210824102803851](images/image-20210824102803851.png)

![image-20210822164154093](images/image-20210822164154093.png)

**稳定性**：

![image-20210822170936992](images/image-20210822170936992.png)

### 1.冒泡排序bubble sort

1. 从头开始比较每一对相邻元素，如果第1个比第2个大，就交换它们的位置 ,(执行完一轮后，最末尾就是那个元素的最大的元素)
2. **稳定**的排序算法

第一轮：![image-20210822164311788](images/image-20210822164311788.png)![image-20210822170716577](images/image-20210822170716577.png)复杂度（平均，最坏，O(n^2)，最好（O(n))  )



优化：

1.在内层循环用一个bool值记录是否进行交换，没有进行交换就直接中止（只有在有序才能优化，不然比普通的时间长，每一次多三个操作，定义，赋值，判断）

2.忽略上一轮曾经找到的最大元素，重复执行步骤一，直到全部元素有序（比第一个优化方式更普遍）

3前两种方式结合，交换则将尾巴赋值为1（最好的）

### 2.原地算法

1.不依赖额外资源或者依赖少数额外资源，仅靠输出覆盖输入

2.空间复杂度O(1)的都可以认为是原地算法

冒泡排序属于In-place

### 3.选择排序

1. 从序列中找出最小的那个元素，然后与数组最开始元素交换位置（执行完一轮后，第一个开始的那个元素就是最大的元素）verse
2. 忽略1中曾经找到的最小元素，重复执行步骤1
3. **不稳定**的算法（1中小于等于也不能保证稳定，2,4, 2,5,1==>1,4,2,5,2）

第一轮：最小的元素在首位

### 4.堆排序 heap sort –对选择排序的优化

![image-20210823104554997](images/image-20210823104554997.png)![image-20210823104833260](images/image-20210823104833260.png)![image-20210823104952157](images/image-20210823104952157.png)![image-20210823105034893](images/image-20210823105034893.png)

执行流程

1.对序列进行原地建堆

2.重复以下操作，直到堆的元素1(N-1次)

交换堆顶元素和尾元素–>堆的元素减1–>对0的位置进行一次siftDown操作（logN)

复杂度（NlogN) 空间复杂度（O(1))

3.不稳定排序

### 5.插入排序 insertion sort

类似于扑克牌排序

![image-20210823111207204](images/image-20210823111207204.png)

执行流程

1.在执行过程中，插入排序会将序列分为2部分

头部是已经拍好序的，尾部是待排列的

2.从头开始扫描每一个元素

每当扫描到一个元素，就将它插入到头部合适的位置，使得头部的数据依然保持有序。

逆序时复杂度（O(n**2))   最好的为O(n) 空间复杂O(1)

3.**稳定**排序

![image-20210823112731329](images/image-20210823112731329.png)

4.优化

将**交换**转为**挪动**（交换为三步，挪动为一步）

将待插元素备份–>头部有序数据比待插元素大的，都朝尾部挪动一个位–>将待插元素放到合适的位置

![image-20210823113432516](images/image-20210823113432516.png)

### 6.二分搜素–插入排序优化

如何确定一个元素在数组中的位置

![image-20210823120702439](images/image-20210823120702439.png)

复杂度（logn)

1.如果存在多个重复的值，返回哪一个值不确定

2.二分搜素优化了比较的次数

3.要求二分搜素返回的插入位置：第一个大于v的元素位置（不能等于，保持稳定性）

![image-20210823141546174](images/image-20210823141546174.png)

### 7.归并排序 merge sort

![image-20220505201110335](/Users/zcz/Desktop/images/image-20220505201110335.png)

1.不断地将当前序列平均分割成2个子序列

直到不能再分割（序列中只剩1个元素）

![1629723882208](images/1629723882208.png)

2.不断地将2个子序列合并成一个有序序列

![1629727411188](images/1629727411188.png)

![1629729017012](images/1629729017012.png)

如果ri提前越界，直接将li之后的所有元素覆盖过去；li提前结束，右边也不用动了

复杂度（T(n)=T(n/2)*2+O(n)=O(nlogn) )最好，最坏，平均都是它

![1629730789469](images/1629730789469.png)

空间复杂度O(n/2+logn)=O(n)

### 8.休眠排序--不提倡

将要排序的数字设为休眠时间，每个数开一个线程，复杂度O(n)

### 9.快速排序 quick sort

![1629731753873](images/1629731753873.png)

![1629732316773](images/1629732316773.png)

复杂度：平均是$nlogn$
![image-20210824101332233](images/image-20210824101332233.png)

### 10.希尔排序 Shell Sort—插入排序的改进

1.把序列看做是一个矩阵，分成m列，逐列进行排序

2.m从某个整数逐渐减为1

3.当m为1时，整个序列完全有序

希尔排序底层一般使用插入排序对每一列进行排序，也有很多资料认为希尔排序是插入排序的改进版

### 11.计数排序

统计每个整数在序列中出现的次数，进而推导出每个整数在有序序列中的索引
![image-20210824105721052](images/image-20210824105721052.png)

1.找出最大值，给出相应存储空间

2.统计次数存入数组

3.依次取出大于1的索引

以上方法问题：1.无法对负值计数 2.极其浪费空间 3.不稳定 4.只能对整数排序，不能对自定义对象排序

改进：空间方面找出最大，最小值，从索引0开始存储次数，这样负值也能存进来，当前数值是max-min+1

![image-20210824111329071](images/image-20210824111329071.png)

### 12.基数排序

![1629780732111](images/1629780732111.png)

![1629783863502](images/1629783863502.png)

### 13.桶排序

![1629784640672](images/1629784640672.png)

## 2.关于B树 B+树 B*树以及红黑树的理解

### 应用场景

红黑树：linux中进程的调度用的是红黑树。数据较小，可以完全放到内存中时，红黑树的时间复杂度比B树低。

B树：B树大量应用在数据库和文件系统当中

B+树：mysql使用B+树作为索引



**二叉树–>二叉搜索树–>二叉平衡树–>红黑树**

AVL:平衡二叉树

### **红黑树**

底层结构是：二叉树

**定义**：红黑树是基于二叉搜索树的，

（1）其根节点和叶子节点为黑色，

（2）每个红色节点的两个子节点一定是黑色，不能有两个红色节点相连，

（3）任一节点到每个叶子节点的路径都包含数量相同的黑节点（黑高）

**变颜色规则**：所有插入的点默认为红色

#### ***插入：***

1.当前父亲节点是黑色直接插入

2.当前父亲节点是红色

​	（1）叔叔是红色，父亲节点和叔叔节点变黑，爷爷变红，指正定位到爷爷节点

​	（2）叔叔节点是黑色，

​				A.LL直接将父节点变为黑色，爷爷节点变红，做一次右旋

​				B.LR左旋成LL,再操作LL

​			



<img src="images/image-20210904102456887.png" alt="image-20210904102456887" style="zoom:50%;" />–<img src="images/image-20210904102954921.png" alt="image-20210904102954921" style="zoom:50%;" />-><img src="images/image-20210904103351047.png" alt="image-20210904103351047" style="zoom:50%;" />



### B**树**(B-树)

B 树是为了磁盘或其它存储设备而设计的一种多叉平衡查找树。

一棵M阶的B树：

（1）每个节点最多有m棵子树

（2）除根节点外，其余非叶子节点至少有ceil(M/2)棵子树，最多有M-1个关键码

（3）所有叶子节点都在同一层

 *一棵含有N个总关键字数的m阶的B树的最大高度是多少?* log_ceil（m/2）{(N+1)/2} + 1 ，log以（m/2）为低，(N+1)/2的对数再加1

### B+树

是应文件系统所需而产生的一种B-tree的变形树。

   (1) 有m个子树的中间节点包含有m个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引；

（2）所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。

（3）**所有的非终端结点可以看成是索引部分**，结点中仅含有其子树根结点中最大（或最小）关键字

**为什么说B+树比B树更适合数据库索引？**

1）B+树的磁盘读写代价更低

　　B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了；

2）B+树查询效率更加稳定

　　由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

3）B+树便于范围查询（最重要的原因，范围查找是数据库的常态）

　　B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低；不懂可以看看这篇解读-》[范围查找](https://zhuanlan.zhihu.com/p/54102723)

### B*树

​    是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；

  B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）；

​    B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针；

​    B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针；

​    所以，B*树分配新结点的概率比B+树要低，空间使用率更高；

## 3.给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?

假如每个url大小为10bytes，那么可以估计每个文件的大小为50G×64=320G，远远大于内存限制的4G，所以不可能将其完全加载到内存中处理，可以采用分治的思想来解决。

　　Step1：遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件(记为a0,a1,...,a999，每个小文件约300M);

　　Step2:遍历文件b，采取和a相同的方式将url分别存储到1000个小文件(记为b0,b1,...,b999);

　　巧妙之处：这样处理后，所有可能相同的url都被保存在对应的小文件(a0vsb0,a1vsb1,...,a999vsb999)中，不对应的小文件不可能有相同的url。然后我们只要求出这个1000对小文件中相同的url即可。

　　Step3：求每对小文件ai和bi中相同的url时，可以把ai的url存储到hash_set/hash_map中。然后遍历bi的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。

https://zhuanlan.zhihu.com/p/24383239