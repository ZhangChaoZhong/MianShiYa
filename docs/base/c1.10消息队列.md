##  2.2消息队列

https://mp.weixin.qq.com/s/1Dwu2Z8Lv88e_Mp1ne7XLg

### 2.2.1 为什么要用消息队列？（优点）

（面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处）

举个例子：下单系统

![image-20210722105134028](E:\Java\images\image-20210722105134028.png)

其实场景有很多，但是比较核心的有3个：**解耦、异步、削峰**

1）异步

> 因为 MQ 的引入，扣积分，扣优惠券，发短信这些步骤全部变成了异步执行，能减少订单支付的整体耗时，提升订单系统的吞吐量。

传统模式：

- 一些非必要的业务逻辑以同步的方式运行，太耗费时间。

中间件模式：

- 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度

**异步，那为什么不用多线程？**

因为用线程去做，你是不是要写代码？扣积分，扣优惠券，发短信，扣库存。。。等等这么多业务要调用这么多的接口，如果**MQ就可以达到解耦的目的**。

2）解耦：

> 引入 MQ 后，订单支付现在只需要关注它最重要的流程：更新订单状态即可。其他不重要的事情全部交给 MQ 来通知。这便是 MQ 解决的最核心的问题：系统解耦。

传统模式：

- 画图，系统间耦合性太强，A系统发送个数据到BC两个系统，接口调用发送，如果还有D系统接入，系统A还需要修改代码，或者B系统不需要了，也要修改代码，过于麻烦！

中间件模式：

- 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。

> 面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦

3）削峰

传统模式：

- 并发量大的时候（5000QPS），所有的请求直接怼到数据库，造成数据库连接异常（数据库直接打死）

中间件模式：

- 系统A慢慢的按照数据库能处理的并发量（2000QPS），从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。

4）我们还可以利用队列本身的顺序性，来满**足消息必须按顺序投递**的场景；利用**队列 + 定时任务**来实现消息的**延时消费** **，日志处理**，**消息通讯（聊天室）**……

**缺点：**

**系统可用性降低**:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那**消息队列挂了**，你的系统不是呵呵了。因此，系统可用性降低

**系统复杂性增加**:要多考虑很多方面的问题，比如**一致性问题（如何保证消息不被重复消费，如何保证消息丢失，消息的顺序性**。因此，需要考虑的东西更多，系统复杂性增大。

### 2.2.2 kafka、activemq、rabbitmq、rocketmq都有什么区别？（**技术选型**）

![preview](E:\Java\images\v2-984876e8232372b9e16180c68927a378_r.jpg)

一般的业务系统要引入MQ，最早大家都用ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用RabbitMQ，但是确实erlang语言阻止了大量的java工程师去深入研究和掌控他，对公司而言，几乎处于不可控的状态，但是确实人是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司，会去用RocketMQ，确实很不错，但是我提醒一下自己想好社区万一突然黄掉的风险，对自己公司技术实力有绝对自信的，我推荐用RocketMQ，否则回去老老实实用RabbitMQ吧，人是活跃开源社区，绝对不会黄

 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择

如果是**大数据领域的实时计算、日志采集**等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范

### 2.2.3 如何保证高可用

（1）rabbitMQ

rabbitmq有三种模式：单机模式，普通集群模式，**镜像集群模式**
 1）单机模式
 就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式。
 2）普通集群模式

![img](E:\Java\images\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODAwODEwMA==,size_16,color_FFFFFF,t_70.png)

3）镜像集群模式
 ![在这里插入图片描述](E:\Java\images\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODAwODEwMA==,size_16,color_FFFFFF,t_70-20220430152617683.png)

（2）kafkaMQ

![图片](E:\Java\images\图片.png)

Kafka是一种纯分布式的中间件。

**一个topic分为多个partion，有多台机器分摊**。Topic在逻辑上可以被认为是一个queue队列，每条消息都必须指定它的topic，为 了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition。

某一台机器宕机了，数据会丢失topic的1/3，那怎么保证高可用？

kafka 0.8以后，提供了HA机制，就是**replica副本机制**。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。**只能读写leader**？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。

写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。**一旦所有follower同步好数据了，就会发送ack给leader**，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。

### 2.2.4 重复消费/幂等性

（1）如何保证消息不被重复消费啊（如何保证消息消费时的幂等性）？

MQ都可能存在消息重复消费

![图片](E:\Java\images\图片-1322153.png)

怎么保证幂等性？

> 幂等性，我通俗点说，就一个数据，或者一个请求，重复请求多次，结果不会改变。

![图片](E:\Java\images\图片-1322617.png)

（1）比如你拿个数据要**写库，你先根据主键**查一下，如果这数据都有了，你就别插入了，update一下好吧

（2）比如你是**写redis**，那没问题了，反正每次都是set，天然幂等性

 （3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的消息id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去**比如redis或者内存Map里查一下**，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

（4）有比如基于**数据库的唯一键**来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为**kafka消费者还没来得及提交offset**，重复数据拿到了以后我们插入的时候，因为**有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据**

### 2.2.5 消息丢失

（1）rabbitmq

![图片](E:\Java\images\图片111111.png)

1）生产者弄丢了数据

生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，**因为网络啥的问题，都有可能**。

- 此时可以选择用rabbitmq提供的**事务功能（同步阻塞）**，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上**吞吐量会下来，因为太耗性能**。

- 所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以**开启confirm模式（异步，推荐）**，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，
  然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。
  如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

2）rabbitmq弄丢了数据

就是rabbitmq自己弄丢了数据，这个你**必须开启rabbitmq的持久化**，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，会自动读取之前存储的数据进行恢复，一般数据不会丢。除非极其罕见的是，rabbitmq**还没持久化，自己就挂了**，可能导致少量数据会丢失的，但是这个概率较小。

设置持久化有两个步骤，**第一个是创建queue的时候将其设置为持久化的**，这样就可以保证rabbitmq**持久化queue的元数据，但是不会持久化queue里的数据**；第二个是发送消息的时候**将消息的deliveryMode设置为2**，就是**将消息设置为持久化**的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。

而且持久化可以跟生产者那边的confirm机制配合起来，**只有消息被持久化到磁盘之后，才会通知生产者ack了**，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。

哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。

3）消费端弄丢了数据

刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。

这个时候得用rabbitmq提供的ack机制，简单来说，就是你**要关闭rabbitmq自动ack**，可以通过一个api来调用就行，然后**将消息消费并处理完再ack**。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。

（2）kafka

![图片](E:\Java\images\图片2222222.png)

1）消费端弄丢了数据

跟rabbitmq一样的

2）kafka弄丢了数据

这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好**还有些数据没有同步，结果此时leader挂了**，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。

生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了

所以此时一般是要求起码设置如下4个参数：

- 给这个**topic**设置replication.factor参数：这个值必须**大于1**，要求每个partition必须有至少2个副本

- 在kafka服务端设置min.insync.replicas参数：这个值必须**大于1**，这个是要求**一个leader**至少感知到有至少**一个follower**还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧

- 在producer端设置**acks=all**：这个要求每条数据，必须是**写入所有leader并同步到所有follwer，才能认为是写成功了**

- 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无**限重试**，卡在这里了

我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失

3）生产者会不会弄丢数据

如果按照上述的思路**设置了ack=all**，一定不会丢，要求是，你的leader接收 到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

### 2.2.6 怎么保证消息的顺序性

先看看顺序会错乱的俩场景

（1）rabbitmq：一个queue，多个consumer，这不明显乱了

![图片01](E:\Java\images\图片012333.png)

（2）kafka：一个topic，一个partition，一个consumer，内部多线程，这不也明显乱了

![图片01](E:\Java\images\图片33333301.png)

那如何保证消息的顺序性呢？简单简单

（1）rabbitmq：**拆分多个queue，每个queue一个consumer**，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

![图片02](E:\Java\images\图片033332.png)

（2）kafka：**一个topic，一个partition**，一个consumer，**内部单线程消费**。但是吞吐量太低了，写N个queue，将具有**相同key的数据都存储在同一个queue**，然后**N个线程分别消费对应内存queue**即可

>  *kafka*只保证单partition有序,并且要保证前一个消息发送成功，后一个消息才能发送

![图片02](E:\Java\images\图片011112.png)

### 2.2.7 消息满了，怎么办？

（1）有几百万消息**持续积压几小时**，说说怎么解决？

![图片](E:\Java\images\图片1223.png)

一般这个时候，只能操作**临时紧急扩容**了，具体操作步骤和思路如下：

1）先**修复consumer的问题**，确保其恢复消费速度，然后将现有cnosumer都停掉

2）新建 一 个topic，**partition**是原来的10倍，临时建立好原先10倍或者20倍的**queue**数量

3）然后写一个临时的分发数据的consumer程序，这个程序部署上去                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    消费积压的数据，消费之后**不做耗时的处理**，**直接均匀轮询写入**临时建立好的10倍数量的queue

4）接着临时**征用10倍的机器来部署consumer**，每一批consumer消费一个**临时queue**的数据，这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据

5）等快速消费完积压数据之后，**得恢复原先部署架构**，重新用原先的consumer机器来消费消息

（2）如何解决消息队列的**延时以及过期失效**问题？

假设你用的是rabbitmq，rabbitmq是可以**设置过期时间（线上是不会设置）**的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。

这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是**丢了大量的消息**。我们可以采取一个方案，就**是批量重导**，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。

这个时候我们就开始写程序，**将丢失的那批数据，写个临时程序，一点一点的查出来**，然后**重新灌入mq**里面去，把白天丢的数据给他补回来。也只能是这样了。

假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次。

（3）如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时**导致mq都快写满了**，咋办？这个还有别的办法吗？

没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。